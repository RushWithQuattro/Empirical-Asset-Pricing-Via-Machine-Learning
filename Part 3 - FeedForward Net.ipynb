{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Emipirical Asset Pricing Part 3 - FeedForward Neural Networks\n",
        "Author: Ren Yang "
      ],
      "metadata": {
        "id": "c5o1zyb7QXRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMhh-QpaUi70",
        "outputId": "917784dd-c99e-4f36-9611-4a1de21922e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU Information"
      ],
      "metadata": {
        "id": "BKsqPta8gNJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import GPUtil\n",
        "from tabulate import tabulate\n",
        "print(\"=\"*40, \"GPU Details\", \"=\"*40)\n",
        "gpus = GPUtil.getGPUs()\n",
        "list_gpus = []\n",
        "for gpu in gpus:\n",
        "    # get the GPU id\n",
        "    gpu_id = gpu.id\n",
        "    # name of GPU\n",
        "    gpu_name = gpu.name\n",
        "    # get % percentage of GPU usage of that GPU\n",
        "    gpu_load = f\"{gpu.load*100}%\"\n",
        "    # get free memory in MB format\n",
        "    gpu_free_memory = f\"{gpu.memoryFree}MB\"\n",
        "    # get used memory\n",
        "    gpu_used_memory = f\"{gpu.memoryUsed}MB\"\n",
        "    # get total memory\n",
        "    gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
        "    # get GPU temperature in Celsius\n",
        "    gpu_temperature = f\"{gpu.temperature} °C\"\n",
        "    gpu_uuid = gpu.uuid\n",
        "    list_gpus.append((\n",
        "        gpu_id, gpu_name, gpu_load, gpu_free_memory, gpu_used_memory,\n",
        "        gpu_total_memory, gpu_temperature, gpu_uuid\n",
        "    ))\n",
        "print(tabulate(list_gpus, headers=(\"id\", \"name\", \"load\", \"free memory\", \"used memory\", \"total memory\", \"temperature\", \"uuid\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dou35XJ6E202",
        "outputId": "400b3a36-5de6-4a0c-f0bf-7382e85d4684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================== GPU Details ========================================\n",
            "  id  name            load    free memory    used memory    total memory    temperature    uuid\n",
            "----  --------------  ------  -------------  -------------  --------------  -------------  ----------------------------------------\n",
            "   0  A100-SXM4-40GB  0.0%    39904.0MB      632.0MB        40536.0MB       24.0 °C        GPU-9bbd1b7a-9bb1-d140-d2f9-fd893edac0d0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06XU0LhcCArS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "import numpy as np\n",
        "import datetime\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGXQpa5gCQZI",
        "outputId": "681e5bc4-a159-4152-ab57-d0c678f0216f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Students/'\n",
        "file_name='openap_macro_merged.parquet.gzip'\n",
        "stock_data=pd.read_parquet(data_dir+file_name)"
      ],
      "metadata": {
        "id": "FtIxMK6vCVG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_sub=stock_data[stock_data['DateYM']>np.datetime64('2000-01-01')].reset_index()"
      ],
      "metadata": {
        "id": "DdZUvKsIDPWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning and Preprocessing\n"
      ],
      "metadata": {
        "id": "Bmfj72JB6nOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmYlvw8yFx7C",
        "outputId": "65d016ee-4b99-4af2-824d-98ec9e52fe82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_sub_3=stock_sub.set_index(['permno','DateYM'],verify_integrity=True).drop('index', axis=1)\n",
        "for i in stock_sub_3.columns[:-1]:\n",
        "  if stock_sub_3[i].nunique()==2: # Check if column is binary\n",
        "    stock_sub_3[i].fillna(0,inplace=True)\n",
        "    stock_sub_3[i]=np.where(stock_sub_3[i]==0,-1,1) \n",
        "  else:\n",
        "    stock_sub_3[i]=stock_sub_3[i].groupby('DateYM').apply(lambda x: x.fillna(0) if np.isnan(x.median()) else x.fillna(x.median()))# fill non binary column NaNs with period cross-sectional median. if period cross-sectional median donesn't exist, fill with 0                    \n",
        "    stock_sub_3[i]=stock_sub_3[i].groupby('DateYM').rank(pct=True).transform(lambda x:2*((x-x.min())/(x.max()-x.min()))-1) \n",
        "                      "
      ],
      "metadata": {
        "id": "Gww6PC1dLaRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rank=stock_sub_3[stock_sub_3.index.get_level_values(1)==pd.to_datetime('2020-12-31')] # rank based on the latest day\n",
        "df_rank['mvel_rank']=df_rank['mvel1'].rank()\n",
        "top_1000_permno=df_rank[df_rank['mvel_rank']>4746].index.get_level_values(0)\n",
        "bot_1000_permno=df_rank[df_rank['mvel_rank']<=1000].index.get_level_values(0)\n",
        "\n",
        "\n",
        "# slice top 1000 stocks\n",
        "top_1000_df=stock_sub_3.loc[top_1000_permno, :]\n",
        "\n",
        "# slice bot 1000 stocks\n",
        "bot_1000_df=stock_sub_3.loc[bot_1000_permno,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F60HXqtJE_yS",
        "outputId": "cd58153a-bdd7-499d-9627-bdea0f829de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define The Structure of The FeedFoward Net and Choices of Hyperparameters"
      ],
      "metadata": {
        "id": "RoLh6W-lgAqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation_func='relu'\n",
        "\n",
        "# we follow te paper of Gu et al,which use ReLu as the activation function in their NN3 model. \n",
        "# According to GU et al, it encourages sparsity in the number of active neurons and follows faster derivative evaluation\n",
        "\n",
        "\n",
        "learning_rate=0.054946\n",
        "# Accroding to Andrej Karpathy's Twitter he said '3e-4 is the best learning rate for Adam, hands down'.\n",
        "\n",
        "\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate)\n",
        "# Adam is a time and memeory effcient version of SGD, which incoprates adaptive learning rate. It also works bettern for noisy data and sparse gradient.\n",
        "\n",
        "\n",
        "kernal_initilizer='he_normal'\n",
        "\n",
        "# according to He et al such kernal intilizer incoperates addaptive std of the disrtibution from which random weight is drawn.\n",
        "# it provides robust convergence when training a deep network. This is similar to Glorot's method but He make it works better with non-linear activation \n",
        "# ReLu, which is what we use in this experiment. \n",
        "\n",
        "\n",
        "Batch_Size=32\n",
        "random_seed=2235\n",
        "\n",
        "\n",
        "\n",
        "def NN3():\n",
        "    tf.keras.utils.set_random_seed(random_seed)\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(units=32, activation=activation_func,\n",
        "                                    kernel_initializer=kernal_initilizer))\n",
        "    model.add(tf.keras.layers.Dense(units=16, activation=activation_func,\n",
        "                                    kernel_initializer=kernal_initilizer))\n",
        "    model.add(tf.keras.layers.Dense(units=8, activation=activation_func,\n",
        "                                    kernel_initializer=kernal_initilizer))\n",
        "    model.add(tf.keras.layers.Dense(units=1))\n",
        "   \n",
        "    model.compile(loss='mse',\n",
        "                 optimizer=optimizer,\n",
        "                 metrics=tfa.metrics.r_square.RSquare())\n",
        "   \n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDpfkOiLMIgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Monthly Pediction on TOP 1000 Stocks using FeedForward Net"
      ],
      "metadata": {
        "id": "0QwpdyNg6vWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train for top 1000 stocks NN3\n",
        "\n",
        "\n",
        "end_of_train=pd.to_datetime('2006-01-31')\n",
        "start_of_validation=end_of_train\n",
        "end_of_validation=start_of_validation+pd.DateOffset(years=3)\n",
        "start_of_test=end_of_validation\n",
        "end_of_test=start_of_test+pd.DateOffset(years=1)\n",
        "\n",
        "\n",
        "\n",
        "cycle_counter=0\n",
        "\n",
        "cycle_r_2_results_top_1000_NN3={}\n",
        "\n",
        "ind=pd.MultiIndex.from_tuples([], names=(u'permno',u'DateYM'))\n",
        "cycle_prediction_results_top_1000_NN3=pd.DataFrame(columns=['ret_pred'],index=ind)\n",
        "\n",
        "\n",
        "while end_of_test<=pd.to_datetime('2020-12-31'):\n",
        "  \n",
        "  \n",
        "  print(f'Cycle({cycle_counter}) starts')\n",
        "#--------------------------------------------------- cycle data prep step ---------------------------------------------- \n",
        "  \n",
        "  cycle_train_val=top_1000_df.loc[top_1000_df.index.get_level_values(1)<end_of_validation]\n",
        "  \n",
        "  cycle_test=top_1000_df.loc[(top_1000_df.index.get_level_values(1)>=start_of_test) & (top_1000_df.index.get_level_values(1)<end_of_test)]\n",
        "  \n",
        "  \n",
        "\n",
        "  cycle_train=cycle_train_val.loc[cycle_train_val.index.get_level_values(1)<start_of_validation,:]\n",
        "\n",
        "  cycle_val=cycle_train_val.loc[cycle_train_val.index.get_level_values(1)>=start_of_validation,:]\n",
        "\n",
        "\n",
        "\n",
        "  # cycle_train=cycle_train_val.loc[:,cycle_train_val['test_fold']==-1]\n",
        "  # cycle_val=cycle_train_val.loc[:,cycle_train_val['test_fold']==0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------- cycle model training step ---------------------------------------------- \n",
        "\n",
        "\n",
        "  early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,\n",
        "                                                     restore_best_weights=True)\n",
        "  \n",
        "\n",
        "  model=NN3()\n",
        "  model.build(input_shape=(None, 214))\n",
        "  model.fit(x=cycle_train.drop(columns=['retadj']),y=cycle_train['retadj']\n",
        "            ,batch_size= 32, # are done on observations(rows)\n",
        "                  epochs=20, # in each epoch, the whole dataset was gone through batch by batch. \n",
        "                  verbose=2,\n",
        "                  validation_data=(cycle_val.drop(columns=['retadj']),\n",
        "                                   cycle_val['retadj']),\n",
        "                  callbacks=[early_stopping_cb])\n",
        "\n",
        "  print(f'Cycle{cycle_counter} model trained')\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "#--------------------------------------------------- cycle model prediction step ---------------------------------------------- \n",
        "  monthly_r_2=0\n",
        "  count=0\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  # iteratively predict every month in test set \n",
        "  for date,df in cycle_test.groupby('DateYM'):\n",
        "    \n",
        "     count+=1\n",
        "     \n",
        "     y_pred=model.predict(df.drop(columns=['retadj']))\n",
        "\n",
        "     monthly_r_2+=metrics.r2_score(y_true=df['retadj'], y_pred=y_pred)\n",
        "\n",
        "     month_pred=pd.DataFrame(columns=['ret_pred'],index=df.index)\n",
        "\n",
        "     month_pred['ret_pred']=y_pred\n",
        "\n",
        "     monthly_r_2+=metrics.r2_score(y_true=df['retadj'], y_pred=y_pred)\n",
        "\n",
        "     cycle_prediction_results_top_1000_NN3=pd.concat([cycle_prediction_results_top_1000_NN3,month_pred])\n",
        "  \n",
        "  cycle_r_2_results_top_1000_NN3[f'Cycle{cycle_counter}Average Monthly R2:']=(monthly_r_2/count)\n",
        "\n",
        "  \n",
        "\n",
        "  print(f'Cycle{cycle_counter} prediction done')\n",
        "  \n",
        "\n",
        "  \n",
        "#---------------------------------------------------  rolling dates updating step ---------------------------------------------- \n",
        "  \n",
        "  cycle_counter+=1\n",
        "  \n",
        "\n",
        "  # move the end of TRAINING set 1 more year to include one more year from the start(2000). VALIDATION set start point and TEST set start point will move back one year subsequently\n",
        "  end_of_train=end_of_train+pd.DateOffset(years=1)\n",
        "  start_of_validation=end_of_train\n",
        "  end_of_validation=start_of_validation+pd.DateOffset(years=3)\n",
        "  start_of_test=end_of_validation\n",
        "  end_of_test=start_of_test+pd.DateOffset(years=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbvAd9OG5Fay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1f5ffa-f88f-466a-ad42-e5be95458bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cycle(0) starts\n",
            "Epoch 1/20\n",
            "1334/1334 - 5s - loss: 79.0915 - r_square: -4.6537e+03 - val_loss: 0.2449 - val_r_square: -2.0442e+01 - 5s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1334/1334 - 4s - loss: 0.0170 - r_square: -1.4058e-03 - val_loss: 0.2446 - val_r_square: -2.0412e+01 - 4s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1334/1334 - 4s - loss: 0.0170 - r_square: -2.2264e-03 - val_loss: 0.2445 - val_r_square: -2.0401e+01 - 4s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1334/1334 - 4s - loss: 0.0171 - r_square: -5.7940e-03 - val_loss: 0.2457 - val_r_square: -2.0512e+01 - 4s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1334/1334 - 4s - loss: 0.0171 - r_square: -8.5675e-03 - val_loss: 0.2445 - val_r_square: -2.0409e+01 - 4s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1334/1334 - 4s - loss: 0.0173 - r_square: -1.8217e-02 - val_loss: 0.2445 - val_r_square: -2.0409e+01 - 4s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1334/1334 - 4s - loss: 0.0174 - r_square: -2.2094e-02 - val_loss: 0.2451 - val_r_square: -2.0460e+01 - 4s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1334/1334 - 4s - loss: 0.0175 - r_square: -3.1948e-02 - val_loss: 0.2448 - val_r_square: -2.0434e+01 - 4s/epoch - 3ms/step\n",
            "Cycle0 model trained\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "Cycle0 prediction done\n",
            "Cycle(1) starts\n",
            "Epoch 1/20\n",
            "1577/1577 - 5s - loss: 2.8217 - r_square: -1.8224e+02 - val_loss: 0.0179 - val_r_square: -1.0304e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1577/1577 - 5s - loss: 0.0154 - r_square: -1.7861e-03 - val_loss: 0.0179 - val_r_square: -1.0015e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1577/1577 - 5s - loss: 0.0155 - r_square: -3.4662e-03 - val_loss: 0.0181 - val_r_square: -2.0957e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1577/1577 - 5s - loss: 0.0155 - r_square: -8.1114e-03 - val_loss: 0.0177 - val_r_square: -9.9933e-04 - 5s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1577/1577 - 5s - loss: 0.0157 - r_square: -1.6652e-02 - val_loss: 0.0180 - val_r_square: -1.4501e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1577/1577 - 5s - loss: 0.0158 - r_square: -2.3104e-02 - val_loss: 0.0181 - val_r_square: -2.3155e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1577/1577 - 5s - loss: 0.0158 - r_square: -2.7448e-02 - val_loss: 0.0183 - val_r_square: -3.3777e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1577/1577 - 5s - loss: 0.0159 - r_square: -3.0798e-02 - val_loss: 0.0178 - val_r_square: -2.1327e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "1577/1577 - 5s - loss: 0.0158 - r_square: -2.6883e-02 - val_loss: 0.0185 - val_r_square: -4.2476e-02 - 5s/epoch - 3ms/step\n",
            "Cycle1 model trained\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "Cycle1 prediction done\n",
            "Cycle(2) starts\n",
            "Epoch 1/20\n",
            "1826/1826 - 6s - loss: 0.1277 - r_square: -7.9677e+00 - val_loss: 0.0185 - val_r_square: -2.9917e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1826/1826 - 5s - loss: 0.0144 - r_square: -9.1612e-03 - val_loss: 0.0186 - val_r_square: -9.9180e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1826/1826 - 5s - loss: 0.0144 - r_square: -1.4072e-02 - val_loss: 0.0196 - val_r_square: -6.4282e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1826/1826 - 5s - loss: 0.0146 - r_square: -2.6604e-02 - val_loss: 0.0185 - val_r_square: -3.2458e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1826/1826 - 5s - loss: 0.0146 - r_square: -2.6990e-02 - val_loss: 0.0192 - val_r_square: -4.0291e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1826/1826 - 5s - loss: 0.0146 - r_square: -2.8163e-02 - val_loss: 0.0185 - val_r_square: -6.5601e-03 - 5s/epoch - 3ms/step\n",
            "Cycle2 model trained\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "Cycle2 prediction done\n",
            "Cycle(3) starts\n",
            "Epoch 1/20\n",
            "2081/2081 - 6s - loss: 1.7245 - r_square: -1.1345e+02 - val_loss: 0.0146 - val_r_square: -1.3992e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2081/2081 - 6s - loss: 0.0151 - r_square: -3.3269e-03 - val_loss: 0.0145 - val_r_square: -9.1846e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2081/2081 - 6s - loss: 0.0152 - r_square: -8.3027e-03 - val_loss: 0.0166 - val_r_square: -1.5406e-01 - 6s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2081/2081 - 6s - loss: 0.0154 - r_square: -2.3899e-02 - val_loss: 0.0145 - val_r_square: -3.9458e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -3.0070e-02 - val_loss: 0.0173 - val_r_square: -2.0150e-01 - 6s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -2.8396e-02 - val_loss: 0.0145 - val_r_square: -4.0381e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -2.7039e-02 - val_loss: 0.0149 - val_r_square: -3.2155e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -3.0513e-02 - val_loss: 0.0144 - val_r_square: -1.4174e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -2.8288e-02 - val_loss: 0.0147 - val_r_square: -1.8244e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -3.1003e-02 - val_loss: 0.0155 - val_r_square: -7.4500e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -3.0695e-02 - val_loss: 0.0144 - val_r_square: -4.4143e-04 - 6s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -3.1689e-02 - val_loss: 0.0149 - val_r_square: -3.2360e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -2.8404e-02 - val_loss: 0.0145 - val_r_square: -2.7844e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "2081/2081 - 6s - loss: 0.0154 - r_square: -2.4827e-02 - val_loss: 0.0147 - val_r_square: -2.0228e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -2.9401e-02 - val_loss: 0.0146 - val_r_square: -1.2059e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "2081/2081 - 6s - loss: 0.0155 - r_square: -3.0510e-02 - val_loss: 0.0146 - val_r_square: -1.1198e-02 - 6s/epoch - 3ms/step\n",
            "Cycle3 model trained\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "Cycle3 prediction done\n",
            "Cycle(4) starts\n",
            "Epoch 1/20\n",
            "2337/2337 - 7s - loss: 1.2769 - r_square: -7.7911e+01 - val_loss: 0.0086 - val_r_square: -9.5367e-06 - 7s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2337/2337 - 6s - loss: 0.0162 - r_square: -3.5124e-03 - val_loss: 0.0086 - val_r_square: -1.7656e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2337/2337 - 6s - loss: 0.0164 - r_square: -1.2282e-02 - val_loss: 0.0101 - val_r_square: -1.7403e-01 - 6s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2337/2337 - 6s - loss: 0.0166 - r_square: -2.3898e-02 - val_loss: 0.0086 - val_r_square: -8.5950e-05 - 6s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2337/2337 - 6s - loss: 0.0166 - r_square: -2.5193e-02 - val_loss: 0.0087 - val_r_square: -1.2310e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2337/2337 - 6s - loss: 0.0167 - r_square: -3.1061e-02 - val_loss: 0.0095 - val_r_square: -9.9952e-02 - 6s/epoch - 3ms/step\n",
            "Cycle4 model trained\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Cycle4 prediction done\n",
            "Cycle(5) starts\n",
            "Epoch 1/20\n",
            "2599/2599 - 8s - loss: 0.9406 - r_square: -5.9727e+01 - val_loss: 0.0078 - val_r_square: -9.1380e-03 - 8s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2599/2599 - 7s - loss: 0.0156 - r_square: -4.4364e-03 - val_loss: 0.0077 - val_r_square: -3.9756e-04 - 7s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2599/2599 - 7s - loss: 0.0157 - r_square: -1.2986e-02 - val_loss: 0.0079 - val_r_square: -2.1466e-02 - 7s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2599/2599 - 7s - loss: 0.0159 - r_square: -2.6461e-02 - val_loss: 0.0080 - val_r_square: -4.2192e-02 - 7s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2599/2599 - 7s - loss: 0.0160 - r_square: -2.9775e-02 - val_loss: 0.0080 - val_r_square: -4.4964e-02 - 7s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2599/2599 - 7s - loss: 0.0160 - r_square: -3.1973e-02 - val_loss: 0.0100 - val_r_square: -2.9363e-01 - 7s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "2599/2599 - 7s - loss: 0.0159 - r_square: -2.9509e-02 - val_loss: 0.0109 - val_r_square: -4.1606e-01 - 7s/epoch - 3ms/step\n",
            "Cycle5 model trained\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 2ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "Cycle5 prediction done\n",
            "Cycle(6) starts\n",
            "Epoch 1/20\n",
            "2868/2868 - 8s - loss: 0.1028 - r_square: -5.8948e+00 - val_loss: 0.0072 - val_r_square: -1.1682e-01 - 8s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2868/2868 - 8s - loss: 0.0152 - r_square: -2.0011e-02 - val_loss: 0.0071 - val_r_square: -9.5818e-02 - 8s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2868/2868 - 8s - loss: 0.0153 - r_square: -2.8937e-02 - val_loss: 0.0066 - val_r_square: -2.3186e-02 - 8s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2868/2868 - 8s - loss: 0.0154 - r_square: -3.0999e-02 - val_loss: 0.0077 - val_r_square: -1.9521e-01 - 8s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2868/2868 - 7s - loss: 0.0154 - r_square: -3.0574e-02 - val_loss: 0.0065 - val_r_square: -8.4002e-03 - 7s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2868/2868 - 8s - loss: 0.0154 - r_square: -2.9344e-02 - val_loss: 0.0065 - val_r_square: -7.4446e-04 - 8s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "2868/2868 - 8s - loss: 0.0154 - r_square: -2.9491e-02 - val_loss: 0.0066 - val_r_square: -2.4583e-02 - 8s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "2868/2868 - 8s - loss: 0.0154 - r_square: -3.2243e-02 - val_loss: 0.0065 - val_r_square: -1.1143e-02 - 8s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "2868/2868 - 7s - loss: 0.0153 - r_square: -2.8101e-02 - val_loss: 0.0066 - val_r_square: -1.6387e-02 - 7s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "2868/2868 - 7s - loss: 0.0154 - r_square: -3.0002e-02 - val_loss: 0.0066 - val_r_square: -2.7170e-02 - 7s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "2868/2868 - 7s - loss: 0.0153 - r_square: -2.6768e-02 - val_loss: 0.0065 - val_r_square: -1.9109e-03 - 7s/epoch - 3ms/step\n",
            "Cycle6 model trained\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "Cycle6 prediction done\n",
            "Cycle(7) starts\n",
            "Epoch 1/20\n",
            "3146/3146 - 9s - loss: 1.1433 - r_square: -7.9302e+01 - val_loss: 0.0067 - val_r_square: -6.7831e-03 - 9s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "3146/3146 - 8s - loss: 0.0143 - r_square: -5.9143e-03 - val_loss: 0.0068 - val_r_square: -2.0444e-02 - 8s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "3146/3146 - 8s - loss: 0.0145 - r_square: -1.9556e-02 - val_loss: 0.0076 - val_r_square: -1.4714e-01 - 8s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "3146/3146 - 8s - loss: 0.0147 - r_square: -3.0890e-02 - val_loss: 0.0071 - val_r_square: -6.5919e-02 - 8s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "3146/3146 - 8s - loss: 0.0147 - r_square: -3.0575e-02 - val_loss: 0.0080 - val_r_square: -2.0836e-01 - 8s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "3146/3146 - 8s - loss: 0.0146 - r_square: -2.7917e-02 - val_loss: 0.0070 - val_r_square: -4.7393e-02 - 8s/epoch - 3ms/step\n",
            "Cycle7 model trained\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "Cycle7 prediction done\n",
            "Cycle(8) starts\n",
            "Epoch 1/20\n",
            "3434/3434 - 10s - loss: 0.0506 - r_square: -2.7244e+00 - val_loss: 0.0083 - val_r_square: -1.2007e-01 - 10s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "3434/3434 - 9s - loss: 0.0139 - r_square: -2.5594e-02 - val_loss: 0.0075 - val_r_square: -1.6915e-02 - 9s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -3.0834e-02 - val_loss: 0.0076 - val_r_square: -2.9089e-02 - 9s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -2.7698e-02 - val_loss: 0.0084 - val_r_square: -1.4130e-01 - 9s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -2.8728e-02 - val_loss: 0.0074 - val_r_square: -4.4607e-03 - 9s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -2.7798e-02 - val_loss: 0.0084 - val_r_square: -1.4012e-01 - 9s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -3.2688e-02 - val_loss: 0.0075 - val_r_square: -9.1389e-03 - 9s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -3.3422e-02 - val_loss: 0.0074 - val_r_square: -6.3099e-03 - 9s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -2.9492e-02 - val_loss: 0.0084 - val_r_square: -1.3877e-01 - 9s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "3434/3434 - 9s - loss: 0.0140 - r_square: -3.2221e-02 - val_loss: 0.0076 - val_r_square: -2.7281e-02 - 9s/epoch - 3ms/step\n",
            "Cycle8 model trained\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 2ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "Cycle8 prediction done\n",
            "Cycle(9) starts\n",
            "Epoch 1/20\n",
            "3735/3735 - 9s - loss: 0.4023 - r_square: -3.0042e+01 - val_loss: 0.0074 - val_r_square: -1.1921e-07 - 9s/epoch - 2ms/step\n",
            "Epoch 2/20\n",
            "3735/3735 - 8s - loss: 0.0132 - r_square: -1.9409e-02 - val_loss: 0.0080 - val_r_square: -8.5574e-02 - 8s/epoch - 2ms/step\n",
            "Epoch 3/20\n",
            "3735/3735 - 8s - loss: 0.0134 - r_square: -3.4102e-02 - val_loss: 0.0082 - val_r_square: -1.0737e-01 - 8s/epoch - 2ms/step\n",
            "Epoch 4/20\n",
            "3735/3735 - 8s - loss: 0.0134 - r_square: -3.2552e-02 - val_loss: 0.0074 - val_r_square: -4.0699e-03 - 8s/epoch - 2ms/step\n",
            "Epoch 5/20\n",
            "3735/3735 - 8s - loss: 0.0134 - r_square: -3.3159e-02 - val_loss: 0.0075 - val_r_square: -1.6936e-02 - 8s/epoch - 2ms/step\n",
            "Epoch 6/20\n",
            "3735/3735 - 8s - loss: 0.0134 - r_square: -3.3414e-02 - val_loss: 0.0083 - val_r_square: -1.2678e-01 - 8s/epoch - 2ms/step\n",
            "Cycle9 model trained\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "Cycle9 prediction done\n",
            "Cycle(10) starts\n",
            "Epoch 1/20\n",
            "4051/4051 - 11s - loss: 0.6566 - r_square: -5.1365e+01 - val_loss: 0.0079 - val_r_square: -1.2015e-02 - 11s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "4051/4051 - 10s - loss: 0.0127 - r_square: -1.2523e-02 - val_loss: 0.0078 - val_r_square: -2.1660e-04 - 10s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "4051/4051 - 10s - loss: 0.0130 - r_square: -3.2800e-02 - val_loss: 0.0079 - val_r_square: -6.7377e-04 - 10s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "4051/4051 - 10s - loss: 0.0130 - r_square: -3.4088e-02 - val_loss: 0.0080 - val_r_square: -1.5012e-02 - 10s/epoch - 2ms/step\n",
            "Epoch 5/20\n",
            "4051/4051 - 10s - loss: 0.0129 - r_square: -3.1446e-02 - val_loss: 0.0090 - val_r_square: -1.4315e-01 - 10s/epoch - 2ms/step\n",
            "Epoch 6/20\n",
            "4051/4051 - 10s - loss: 0.0129 - r_square: -3.2423e-02 - val_loss: 0.0079 - val_r_square: -8.0740e-04 - 10s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "4051/4051 - 10s - loss: 0.0129 - r_square: -3.0986e-02 - val_loss: 0.0079 - val_r_square: -6.4781e-03 - 10s/epoch - 3ms/step\n",
            "Cycle10 model trained\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "31/31 [==============================] - 0s 1ms/step\n",
            "31/31 [==============================] - 0s 1ms/step\n",
            "31/31 [==============================] - 0s 2ms/step\n",
            "31/31 [==============================] - 0s 1ms/step\n",
            "31/31 [==============================] - 0s 1ms/step\n",
            "31/31 [==============================] - 0s 1ms/step\n",
            "Cycle10 prediction done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monthly Pediction on BOT 1000 Stocks using FeedForward Net"
      ],
      "metadata": {
        "id": "_keNJk6u69Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train for bot 1000 stocks NN3\n",
        "\n",
        "\n",
        "end_of_train=pd.to_datetime('2006-01-31')\n",
        "start_of_validation=end_of_train\n",
        "end_of_validation=start_of_validation+pd.DateOffset(years=3)\n",
        "start_of_test=end_of_validation\n",
        "end_of_test=start_of_test+pd.DateOffset(years=1)\n",
        "\n",
        "\n",
        "\n",
        "cycle_counter=0\n",
        "\n",
        "cycle_r_2_results_bot_1000_NN3={}\n",
        "\n",
        "\n",
        "ind=pd.MultiIndex.from_tuples([], names=(u'permno',u'DateYM'))\n",
        "cycle_prediction_results_bot_1000_NN3=pd.DataFrame(columns=['ret_pred'],index=ind)\n",
        "\n",
        "\n",
        "while end_of_test<=pd.to_datetime('2020-12-31'):\n",
        "  \n",
        "  \n",
        "  print(f'Cycle({cycle_counter}) starts')\n",
        "#--------------------------------------------------- cycle data prep step ---------------------------------------------- \n",
        "  \n",
        "  cycle_train_val=bot_1000_df.loc[bot_1000_df.index.get_level_values(1)<end_of_validation]\n",
        "  \n",
        "  cycle_test=bot_1000_df.loc[(bot_1000_df.index.get_level_values(1)>=start_of_test) & (bot_1000_df.index.get_level_values(1)<end_of_test)]\n",
        "  \n",
        "  \n",
        "\n",
        "  cycle_train=cycle_train_val.loc[cycle_train_val.index.get_level_values(1)<start_of_validation,:]\n",
        "\n",
        "  cycle_val=cycle_train_val.loc[cycle_train_val.index.get_level_values(1)>=start_of_validation,:]\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------- cycle model training step ---------------------------------------------- \n",
        "\n",
        "  early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,\n",
        "                                                     restore_best_weights=True)\n",
        "  \n",
        "\n",
        "  model=NN3()\n",
        "  model.build(input_shape=(None, 214))\n",
        "  model.fit(x=cycle_train.drop(columns=['retadj']),y=cycle_train['retadj']\n",
        "            ,batch_size= 32, # are done on observations(rows)\n",
        "                  epochs=20, # in each epoch, the whole dataset was gone through batch by batch. \n",
        "                  verbose=2,\n",
        "                  validation_data=(cycle_val.drop(columns=['retadj']),\n",
        "                                   cycle_val['retadj']),\n",
        "                  callbacks=[early_stopping_cb])\n",
        "\n",
        "  print(f'Cycle{cycle_counter} model trained')\n",
        "  \n",
        "\n",
        "  \n",
        "#--------------------------------------------------- cycle model prediction step ---------------------------------------------- \n",
        "  monthly_r_2=0\n",
        "  count=0\n",
        "  \n",
        "  # iteratively predict every month in test set \n",
        "  for date,df in cycle_test.groupby('DateYM'):\n",
        "   \n",
        "     count+=1\n",
        "     \n",
        "     y_pred=model.predict(df.drop(columns=['retadj']))\n",
        "     \n",
        "     monthly_r_2+=metrics.r2_score(y_true=df['retadj'], y_pred=y_pred)\n",
        "\n",
        "     month_pred=pd.DataFrame(columns=['ret_pred'],index=df.index)\n",
        "\n",
        "     month_pred['ret_pred']=y_pred\n",
        "\n",
        "     cycle_prediction_results_bot_1000_NN3=pd.concat([cycle_prediction_results_bot_1000_NN3,month_pred])\n",
        "  \n",
        "  \n",
        "  cycle_r_2_results_bot_1000_NN3[f'Cycle{cycle_counter}Average Monthly R2:']=(monthly_r_2/count)\n",
        "\n",
        "  \n",
        "\n",
        "  print(f'Cycle{cycle_counter} prediction done')\n",
        "  \n",
        "\n",
        "  \n",
        "#---------------------------------------------------  rolling dates updating step ---------------------------------------------- \n",
        "  \n",
        "  cycle_counter+=1\n",
        "  \n",
        "\n",
        "  # move the end of TRAINING set 1 more year to include one more year from the start(2000). VALIDATION set start point and TEST set start point will move back one year subsequently\n",
        "  end_of_train=end_of_train+pd.DateOffset(years=1)\n",
        "  start_of_validation=end_of_train\n",
        "  end_of_validation=start_of_validation+pd.DateOffset(years=3)\n",
        "  start_of_test=end_of_validation\n",
        "  end_of_test=start_of_test+pd.DateOffset(years=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyqdoSiBKDyO",
        "outputId": "29fad3ca-eacb-4739-9ced-949e21968646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cycle(0) starts\n",
            "Epoch 1/20\n",
            "742/742 - 3s - loss: 0.4370 - r_square: -1.0665e+01 - val_loss: 0.6266 - val_r_square: -2.2362e+01 - 3s/epoch - 4ms/step\n",
            "Epoch 2/20\n",
            "742/742 - 2s - loss: 0.0382 - r_square: -2.0222e-02 - val_loss: 0.6294 - val_r_square: -2.2465e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "742/742 - 2s - loss: 0.0380 - r_square: -1.4461e-02 - val_loss: 0.6257 - val_r_square: -2.2331e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "742/742 - 2s - loss: 0.0380 - r_square: -1.3407e-02 - val_loss: 0.6246 - val_r_square: -2.2290e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "742/742 - 2s - loss: 0.0379 - r_square: -1.0473e-02 - val_loss: 0.6256 - val_r_square: -2.2327e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "742/742 - 2s - loss: 0.0379 - r_square: -1.1038e-02 - val_loss: 0.6231 - val_r_square: -2.2231e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "742/742 - 2s - loss: 0.0380 - r_square: -1.4473e-02 - val_loss: 0.6238 - val_r_square: -2.2258e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "742/742 - 2s - loss: 0.0381 - r_square: -1.6762e-02 - val_loss: 0.6231 - val_r_square: -2.2232e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "742/742 - 2s - loss: 0.0380 - r_square: -1.4900e-02 - val_loss: 0.6245 - val_r_square: -2.2283e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "742/742 - 2s - loss: 0.0383 - r_square: -2.1363e-02 - val_loss: 0.6257 - val_r_square: -2.2331e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "742/742 - 2s - loss: 0.0383 - r_square: -2.3062e-02 - val_loss: 0.6228 - val_r_square: -2.2222e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "742/742 - 2s - loss: 0.0381 - r_square: -1.7724e-02 - val_loss: 0.6236 - val_r_square: -2.2250e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "742/742 - 2s - loss: 0.0380 - r_square: -1.4108e-02 - val_loss: 0.6237 - val_r_square: -2.2253e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "742/742 - 2s - loss: 0.0382 - r_square: -1.9485e-02 - val_loss: 0.6235 - val_r_square: -2.2248e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "742/742 - 2s - loss: 0.0380 - r_square: -1.3990e-02 - val_loss: 0.6235 - val_r_square: -2.2247e+01 - 2s/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "742/742 - 2s - loss: 0.0383 - r_square: -2.0935e-02 - val_loss: 0.6282 - val_r_square: -2.2423e+01 - 2s/epoch - 3ms/step\n",
            "Cycle0 model trained\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "Cycle0 prediction done\n",
            "Cycle(1) starts\n",
            "Epoch 1/20\n",
            "885/885 - 3s - loss: 5.0695 - r_square: -1.4434e+02 - val_loss: 0.0813 - val_r_square: -9.6686e-01 - 3s/epoch - 4ms/step\n",
            "Epoch 2/20\n",
            "885/885 - 3s - loss: 0.0350 - r_square: -2.1456e-03 - val_loss: 0.0815 - val_r_square: -9.7212e-01 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "885/885 - 3s - loss: 0.0350 - r_square: -3.1384e-03 - val_loss: 0.0812 - val_r_square: -9.6453e-01 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "885/885 - 3s - loss: 0.0350 - r_square: -4.0358e-03 - val_loss: 0.0815 - val_r_square: -9.7242e-01 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "885/885 - 3s - loss: 0.0352 - r_square: -8.0074e-03 - val_loss: 0.0813 - val_r_square: -9.6592e-01 - 3s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "885/885 - 3s - loss: 0.0352 - r_square: -9.6651e-03 - val_loss: 0.0812 - val_r_square: -9.6484e-01 - 3s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "885/885 - 3s - loss: 0.0353 - r_square: -1.2965e-02 - val_loss: 0.0812 - val_r_square: -9.6520e-01 - 3s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "885/885 - 3s - loss: 0.0354 - r_square: -1.4314e-02 - val_loss: 0.0822 - val_r_square: -9.8752e-01 - 3s/epoch - 3ms/step\n",
            "Cycle1 model trained\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "Cycle1 prediction done\n",
            "Cycle(2) starts\n",
            "Epoch 1/20\n",
            "1037/1037 - 3s - loss: 0.5291 - r_square: -1.5226e+01 - val_loss: 0.0421 - val_r_square: -9.7752e-06 - 3s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1037/1037 - 3s - loss: 0.0327 - r_square: -2.8013e-03 - val_loss: 0.0422 - val_r_square: -1.5988e-03 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1037/1037 - 3s - loss: 0.0328 - r_square: -4.9232e-03 - val_loss: 0.0422 - val_r_square: -1.8382e-04 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1037/1037 - 3s - loss: 0.0328 - r_square: -7.1809e-03 - val_loss: 0.0423 - val_r_square: -2.4972e-03 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1037/1037 - 3s - loss: 0.0331 - r_square: -1.5063e-02 - val_loss: 0.0426 - val_r_square: -1.0788e-02 - 3s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1037/1037 - 3s - loss: 0.0333 - r_square: -2.0746e-02 - val_loss: 0.0450 - val_r_square: -6.7581e-02 - 3s/epoch - 3ms/step\n",
            "Cycle2 model trained\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Cycle2 prediction done\n",
            "Cycle(3) starts\n",
            "Epoch 1/20\n",
            "1200/1200 - 4s - loss: 1.9366 - r_square: -5.6639e+01 - val_loss: 0.0370 - val_r_square: -4.7839e-04 - 4s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1200/1200 - 3s - loss: 0.0337 - r_square: -2.5767e-03 - val_loss: 0.0370 - val_r_square: -1.8922e-03 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1200/1200 - 3s - loss: 0.0337 - r_square: -4.1295e-03 - val_loss: 0.0375 - val_r_square: -1.5924e-02 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1200/1200 - 3s - loss: 0.0339 - r_square: -8.2943e-03 - val_loss: 0.0387 - val_r_square: -4.6461e-02 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1200/1200 - 3s - loss: 0.0340 - r_square: -1.1460e-02 - val_loss: 0.0378 - val_r_square: -2.2820e-02 - 3s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1200/1200 - 3s - loss: 0.0342 - r_square: -1.7023e-02 - val_loss: 0.0372 - val_r_square: -6.1769e-03 - 3s/epoch - 3ms/step\n",
            "Cycle3 model trained\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "Cycle3 prediction done\n",
            "Cycle(4) starts\n",
            "Epoch 1/20\n",
            "1366/1366 - 5s - loss: 0.2864 - r_square: -6.6985e+00 - val_loss: 0.0277 - val_r_square: -8.9834e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1366/1366 - 4s - loss: 0.0374 - r_square: -5.4358e-03 - val_loss: 0.0275 - val_r_square: -2.5964e-03 - 4s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1366/1366 - 4s - loss: 0.0375 - r_square: -7.8319e-03 - val_loss: 0.0277 - val_r_square: -9.6627e-03 - 4s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1366/1366 - 4s - loss: 0.0377 - r_square: -1.3743e-02 - val_loss: 0.0276 - val_r_square: -6.7947e-03 - 4s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1366/1366 - 4s - loss: 0.0380 - r_square: -2.2443e-02 - val_loss: 0.0292 - val_r_square: -6.5083e-02 - 4s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1366/1366 - 4s - loss: 0.0379 - r_square: -1.7991e-02 - val_loss: 0.0299 - val_r_square: -9.0732e-02 - 4s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1366/1366 - 4s - loss: 0.0380 - r_square: -2.0180e-02 - val_loss: 0.0293 - val_r_square: -6.9978e-02 - 4s/epoch - 3ms/step\n",
            "Cycle4 model trained\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "Cycle4 prediction done\n",
            "Cycle(5) starts\n",
            "Epoch 1/20\n",
            "1540/1540 - 5s - loss: 0.3352 - r_square: -8.3818e+00 - val_loss: 0.0281 - val_r_square: -2.1458e-06 - 5s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1540/1540 - 4s - loss: 0.0360 - r_square: -6.8675e-03 - val_loss: 0.0286 - val_r_square: -1.8673e-02 - 4s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1540/1540 - 4s - loss: 0.0361 - r_square: -1.1103e-02 - val_loss: 0.0281 - val_r_square: -5.5313e-05 - 4s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1540/1540 - 4s - loss: 0.0363 - r_square: -1.6750e-02 - val_loss: 0.0282 - val_r_square: -4.5193e-03 - 4s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1540/1540 - 4s - loss: 0.0364 - r_square: -1.8767e-02 - val_loss: 0.0283 - val_r_square: -9.6853e-03 - 4s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1540/1540 - 4s - loss: 0.0364 - r_square: -1.9176e-02 - val_loss: 0.0326 - val_r_square: -1.6329e-01 - 4s/epoch - 3ms/step\n",
            "Cycle5 model trained\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "Cycle5 prediction done\n",
            "Cycle(6) starts\n",
            "Epoch 1/20\n",
            "1722/1722 - 5s - loss: 0.8058 - r_square: -2.2242e+01 - val_loss: 0.0308 - val_r_square: -1.6856e-04 - 5s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1722/1722 - 4s - loss: 0.0348 - r_square: -3.0718e-03 - val_loss: 0.0308 - val_r_square: -1.3733e-04 - 4s/epoch - 2ms/step\n",
            "Epoch 3/20\n",
            "1722/1722 - 4s - loss: 0.0349 - r_square: -6.2281e-03 - val_loss: 0.0338 - val_r_square: -1.0004e-01 - 4s/epoch - 2ms/step\n",
            "Epoch 4/20\n",
            "1722/1722 - 4s - loss: 0.0351 - r_square: -1.2363e-02 - val_loss: 0.0325 - val_r_square: -5.5692e-02 - 4s/epoch - 2ms/step\n",
            "Epoch 5/20\n",
            "1722/1722 - 4s - loss: 0.0353 - r_square: -1.9271e-02 - val_loss: 0.0326 - val_r_square: -5.9267e-02 - 4s/epoch - 2ms/step\n",
            "Epoch 6/20\n",
            "1722/1722 - 4s - loss: 0.0355 - r_square: -2.4976e-02 - val_loss: 0.0317 - val_r_square: -3.1744e-02 - 4s/epoch - 2ms/step\n",
            "Epoch 7/20\n",
            "1722/1722 - 4s - loss: 0.0353 - r_square: -1.9167e-02 - val_loss: 0.0308 - val_r_square: -2.0504e-05 - 4s/epoch - 2ms/step\n",
            "Epoch 8/20\n",
            "1722/1722 - 4s - loss: 0.0354 - r_square: -2.1582e-02 - val_loss: 0.0309 - val_r_square: -5.7555e-03 - 4s/epoch - 2ms/step\n",
            "Epoch 9/20\n",
            "1722/1722 - 4s - loss: 0.0354 - r_square: -2.0759e-02 - val_loss: 0.0310 - val_r_square: -7.5548e-03 - 4s/epoch - 2ms/step\n",
            "Epoch 10/20\n",
            "1722/1722 - 4s - loss: 0.0354 - r_square: -2.1071e-02 - val_loss: 0.0310 - val_r_square: -9.6507e-03 - 4s/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "1722/1722 - 4s - loss: 0.0354 - r_square: -2.0040e-02 - val_loss: 0.0329 - val_r_square: -6.9058e-02 - 4s/epoch - 2ms/step\n",
            "Epoch 12/20\n",
            "1722/1722 - 4s - loss: 0.0355 - r_square: -2.3643e-02 - val_loss: 0.0312 - val_r_square: -1.3256e-02 - 4s/epoch - 2ms/step\n",
            "Cycle6 model trained\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "20/20 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Cycle6 prediction done\n",
            "Cycle(7) starts\n",
            "Epoch 1/20\n",
            "1912/1912 - 6s - loss: 0.5350 - r_square: -1.4548e+01 - val_loss: 0.0312 - val_r_square: -4.5016e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1912/1912 - 5s - loss: 0.0346 - r_square: -4.1009e-03 - val_loss: 0.0311 - val_r_square: -2.0374e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1912/1912 - 5s - loss: 0.0347 - r_square: -9.7189e-03 - val_loss: 0.0337 - val_r_square: -8.5426e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1912/1912 - 5s - loss: 0.0350 - r_square: -1.6266e-02 - val_loss: 0.0322 - val_r_square: -3.7804e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1912/1912 - 5s - loss: 0.0351 - r_square: -1.9352e-02 - val_loss: 0.0311 - val_r_square: -1.4256e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1912/1912 - 5s - loss: 0.0350 - r_square: -1.8266e-02 - val_loss: 0.0310 - val_r_square: -6.9129e-04 - 5s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1912/1912 - 5s - loss: 0.0352 - r_square: -2.1584e-02 - val_loss: 0.0315 - val_r_square: -1.7005e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1912/1912 - 5s - loss: 0.0350 - r_square: -1.7816e-02 - val_loss: 0.0312 - val_r_square: -4.8690e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "1912/1912 - 5s - loss: 0.0350 - r_square: -1.6481e-02 - val_loss: 0.0310 - val_r_square: -3.7408e-04 - 5s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "1912/1912 - 5s - loss: 0.0350 - r_square: -1.8464e-02 - val_loss: 0.0315 - val_r_square: -1.5025e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "1912/1912 - 5s - loss: 0.0352 - r_square: -2.2569e-02 - val_loss: 0.0310 - val_r_square: -2.1839e-04 - 5s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "1912/1912 - 5s - loss: 0.0353 - r_square: -2.5302e-02 - val_loss: 0.0316 - val_r_square: -1.8063e-02 - 5s/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "1912/1912 - 5s - loss: 0.0352 - r_square: -2.3120e-02 - val_loss: 0.0312 - val_r_square: -5.0123e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "1912/1912 - 5s - loss: 0.0351 - r_square: -1.9825e-02 - val_loss: 0.0313 - val_r_square: -8.7733e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "1912/1912 - 5s - loss: 0.0352 - r_square: -2.3152e-02 - val_loss: 0.0311 - val_r_square: -3.2468e-03 - 5s/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "1912/1912 - 5s - loss: 0.0352 - r_square: -2.1869e-02 - val_loss: 0.0313 - val_r_square: -8.4270e-03 - 5s/epoch - 3ms/step\n",
            "Cycle7 model trained\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "22/22 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "Cycle7 prediction done\n",
            "Cycle(8) starts\n",
            "Epoch 1/20\n",
            "2112/2112 - 6s - loss: 0.3041 - r_square: -8.0379e+00 - val_loss: 0.0374 - val_r_square: -5.2524e-04 - 6s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2112/2112 - 6s - loss: 0.0339 - r_square: -8.5181e-03 - val_loss: 0.0374 - val_r_square: -5.1284e-04 - 6s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2112/2112 - 6s - loss: 0.0341 - r_square: -1.2891e-02 - val_loss: 0.0386 - val_r_square: -3.3190e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2112/2112 - 6s - loss: 0.0343 - r_square: -1.9009e-02 - val_loss: 0.0386 - val_r_square: -3.4127e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2112/2112 - 6s - loss: 0.0344 - r_square: -2.2552e-02 - val_loss: 0.0376 - val_r_square: -5.4184e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2112/2112 - 6s - loss: 0.0344 - r_square: -2.1532e-02 - val_loss: 0.0374 - val_r_square: -9.5463e-04 - 6s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "2112/2112 - 6s - loss: 0.0343 - r_square: -1.9454e-02 - val_loss: 0.0401 - val_r_square: -7.2063e-02 - 6s/epoch - 3ms/step\n",
            "Cycle8 model trained\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Cycle8 prediction done\n",
            "Cycle(9) starts\n",
            "Epoch 1/20\n",
            "2331/2331 - 7s - loss: 1.9547 - r_square: -5.7096e+01 - val_loss: 0.0410 - val_r_square: -5.9032e-04 - 7s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2331/2331 - 6s - loss: 0.0338 - r_square: -4.3063e-03 - val_loss: 0.0414 - val_r_square: -9.2505e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2331/2331 - 6s - loss: 0.0340 - r_square: -1.1536e-02 - val_loss: 0.0414 - val_r_square: -8.4267e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2331/2331 - 6s - loss: 0.0343 - r_square: -1.9309e-02 - val_loss: 0.0411 - val_r_square: -1.1747e-03 - 6s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2331/2331 - 6s - loss: 0.0344 - r_square: -2.2325e-02 - val_loss: 0.0417 - val_r_square: -1.6384e-02 - 6s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2331/2331 - 6s - loss: 0.0344 - r_square: -2.2009e-02 - val_loss: 0.0411 - val_r_square: -1.7095e-03 - 6s/epoch - 3ms/step\n",
            "Cycle9 model trained\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "Cycle9 prediction done\n",
            "Cycle(10) starts\n",
            "Epoch 1/20\n",
            "2570/2570 - 8s - loss: 4.7148 - r_square: -1.3950e+02 - val_loss: 0.0459 - val_r_square: -6.7556e-04 - 8s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "2570/2570 - 7s - loss: 0.0338 - r_square: -6.9145e-03 - val_loss: 0.0467 - val_r_square: -1.6379e-02 - 7s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "2570/2570 - 7s - loss: 0.0344 - r_square: -2.4393e-02 - val_loss: 0.0463 - val_r_square: -8.4810e-03 - 7s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "2570/2570 - 7s - loss: 0.0346 - r_square: -3.1649e-02 - val_loss: 0.0461 - val_r_square: -4.9808e-03 - 7s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "2570/2570 - 7s - loss: 0.0347 - r_square: -3.4114e-02 - val_loss: 0.0535 - val_r_square: -1.6571e-01 - 7s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "2570/2570 - 7s - loss: 0.0348 - r_square: -3.7312e-02 - val_loss: 0.0463 - val_r_square: -8.7988e-03 - 7s/epoch - 3ms/step\n",
            "Cycle10 model trained\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "Cycle10 prediction done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cycle_r_2_results_top_1000_NN3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_7GWVMHksvo",
        "outputId": "5812381f-dc35-4889-d392-06f3473653bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cycle0Average Monthly R2:': -30.30769296068681,\n",
              " 'Cycle1Average Monthly R2:': -1.1567069403945653,\n",
              " 'Cycle2Average Monthly R2:': -0.7745689272094339,\n",
              " 'Cycle3Average Monthly R2:': -0.329674132961212,\n",
              " 'Cycle4Average Monthly R2:': -0.3351099444449705,\n",
              " 'Cycle5Average Monthly R2:': -0.38009836984636514,\n",
              " 'Cycle6Average Monthly R2:': -0.599493801192695,\n",
              " 'Cycle7Average Monthly R2:': -0.3764508123490177,\n",
              " 'Cycle8Average Monthly R2:': -0.05866163541322381,\n",
              " 'Cycle9Average Monthly R2:': -0.6912480604129696,\n",
              " 'Cycle10Average Monthly R2:': -0.4992494762473753}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cycle_r_2_results_bot_1000_NN3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM85dR4Kk7D3",
        "outputId": "f58722aa-b99a-4e61-9b00-b9b2fa3ef7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cycle0Average Monthly R2:': -732.7629960875937,\n",
              " 'Cycle1Average Monthly R2:': -9.595971475127143,\n",
              " 'Cycle2Average Monthly R2:': -0.14981429310452002,\n",
              " 'Cycle3Average Monthly R2:': -0.06581482984232188,\n",
              " 'Cycle4Average Monthly R2:': -0.054282163581970085,\n",
              " 'Cycle5Average Monthly R2:': -0.05272595947826233,\n",
              " 'Cycle6Average Monthly R2:': -0.06412571758627696,\n",
              " 'Cycle7Average Monthly R2:': -0.057865800841863047,\n",
              " 'Cycle8Average Monthly R2:': -0.028179740189297624,\n",
              " 'Cycle9Average Monthly R2:': -0.09664572841686776,\n",
              " 'Cycle10Average Monthly R2:': -0.03727599362885622}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}